{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ggdCp3ul5rqC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import e,sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import leastsq\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pyFTS.models.nonstationary import nsfts\n",
    "from pyFTS.benchmarks import Measures\n",
    "from pyFTS.benchmarks import Measures\n",
    "import matplotlib.pyplot as plt\n",
    "from pyFTS.common import Util\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "import datetime\n",
    "import statistics\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import statistics\n",
    "sys.path.append(\"/home/hugo/projetos-doutorado/mimo_emb_fts/src/\")\n",
    "\n",
    "from embfts.util.DataSetUtil import DataSetUtil\n",
    "from embfts.util.StatisticsUtil import StatisticsUtil\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-rVabXnm5_SI"
   },
   "outputs": [],
   "source": [
    "data_set_util = DataSetUtil()\n",
    "statistics_util = StatisticsUtil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PUayPZSy6L5W"
   },
   "outputs": [],
   "source": [
    "def cal_nrmse(rmse, y):\n",
    "    x = max(y)-min(y)\n",
    "    return (rmse/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaxSUZOy6j_L"
   },
   "outputs": [],
   "source": [
    "x,y=reframed.loc[:,:],reframed.loc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qrhm9ld6kJK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "# Get the number of inputs and outputs from the dataset\n",
    "df_trainx=x_train.loc[:,'use(t-1)':'precipProbability(t-1)']\n",
    "df_testx=x_test.loc[:,'use(t-1)':'precipProbability(t-1)']\n",
    "df_trainy=y_train.loc[:,'use(t-1)':'precipProbability(t-1)']\n",
    "df_original=y_test.loc[:,'use(t)':'precipProbability(t)']\n",
    "\n",
    "n_inputs, n_outputs = df_trainx.shape[1], df_trainy.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFsKrpPU-lb3"
   },
   "outputs": [],
   "source": [
    "print(n_outputs,n_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYQne2bYjxS7"
   },
   "source": [
    "##Randomized_Grid_SearcgCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml5EA-uz7OS1"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "model = MultiOutputRegressor(GradientBoostingRegressor())\n",
    "\n",
    "hyperparameters = dict(estimator__learning_rate=[0.05, 0.1, 0.2, 0.5, 0.9],\n",
    "                     estimator__n_estimators=[20, 50, 100, 200, 300],\n",
    "                     estimator__criterion=['friedman_mse', 'mse'], estimator__min_samples_split=[2,3,5,7,9],\n",
    "                     estimator__max_depth=[2,5,10,20,30], estimator__min_samples_leaf=[1,2,3,4,5,7,9])\n",
    "\n",
    "randomized_search = RandomizedSearchCV(model, hyperparameters, random_state=0, n_iter=5, scoring=None,\n",
    "                                       n_jobs=2, refit=True, cv=5, verbose=True,\n",
    "                                       pre_dispatch='2*n_jobs', error_score='raise', return_train_score=True)\n",
    "\n",
    "hyperparameters_tuning = randomized_search.fit(df_trainx, df_trainy)\n",
    "print('Best Parameters = {}'.format(hyperparameters_tuning.best_params_))\n",
    "\n",
    "tuned_model = hyperparameters_tuning.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yle4K6ZSoAyK"
   },
   "outputs": [],
   "source": [
    "y_p=tuned_model.predict(df_testx)\n",
    "columns=df_original.columns\n",
    "y_p=pd.DataFrame(y_p,columns=columns)\n",
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oN3Z1H-IrFlC"
   },
   "outputs": [],
   "source": [
    "col=df_original.columns\n",
    "result = {\n",
    "        \n",
    "         \"rmse\": [],\n",
    "         \n",
    "         \"mae\": [],\n",
    "         \"r2\": [],\n",
    "         \"mape\":[],\n",
    "         \"variable\":[]\n",
    "    }\n",
    "    \n",
    "final_result = {\n",
    "        \n",
    "         \"rmse\": [],\n",
    "         \n",
    "         \"mae\": [],\n",
    "         \"r2\": [],\n",
    "         \"mape\":[],\n",
    "         \"variable\":[]}\n",
    "for col in col: \n",
    "  original = df_original[col].values\n",
    "  forecast = y_p[col].values\n",
    "  mae = round(mean_absolute_error(original,forecast),3)\n",
    "  r2 = round(r2_score(original,forecast),3)\n",
    "  rmse = round(mean_squared_error(original,forecast,squared=False),3)             \n",
    "  mape = round(mean_absolute_percentage_error(original,forecast),3)\n",
    "\n",
    "  result[\"rmse\"].append(rmse)\n",
    "  result[\"mae\"].append(mae)\n",
    "  result[\"r2\"].append(r2)\n",
    "  result[\"mape\"].append(mape)\n",
    "  \n",
    "  result[\"variable\"].append(col)\n",
    "        \n",
    "measures = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OX4hoqOaoXYj"
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "final_result = {\n",
    "    \"variable\": [],\n",
    "    \"rmse\": [],\n",
    "    # \"nrmse\": [],\n",
    "    \"mae\": [],\n",
    "    \"r2\": [],\n",
    "    \"mape\":[]\n",
    "}\n",
    "\n",
    "\n",
    "var = measures.groupby(\"variable\")\n",
    "\n",
    "for col in columns:\n",
    "    \n",
    "    var_agr = var.get_group(col)\n",
    "           \n",
    "    rmse = round(statistics.mean(var_agr.loc[:,'rmse']),3)\n",
    "    # nrmse = round(statistics.mean(var_agr.loc[:,'nrmse']),3)\n",
    "    mae = round(statistics.mean(var_agr.loc[:,'mae']),3)\n",
    "    r2 = round(statistics.mean(var_agr.loc[:,'r2']),3)\n",
    "    mape = round(statistics.mean(var_agr.loc[:,'mape']),3)\n",
    "\n",
    "    final_result[\"variable\"].append(col)\n",
    "    final_result[\"rmse\"].append(rmse)\n",
    "    # final_result[\"nrmse\"].append(nrmse)\n",
    "    final_result[\"mae\"].append(mae)\n",
    "    final_result[\"r2\"].append(r2)\n",
    "    final_result[\"mape\"].append(mape)\n",
    "        \n",
    "    print(f'Results: {(col,rmse,mae,r2,mape)}')\n",
    "        \n",
    "        \n",
    "final_measures_kpca = pd.DataFrame(final_result) \n",
    "\n",
    "print(\"Statistics MIMO (test): \")\n",
    "final_measures_kpca"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MIMO_regressor_GB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
