{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggdCp3ul5rqC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import e,sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import leastsq\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l01o9PBG5xaX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame) \n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMaFtvVOKtOS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/content/smart_home_data.csv', sep=',')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rVabXnm5_SI"
   },
   "outputs": [],
   "source": [
    "df=df[:-1]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUayPZSy6L5W"
   },
   "outputs": [],
   "source": [
    "df.columns = [col.replace(' [kW]', '') for col in df.columns]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UOmNeXR6QbG"
   },
   "outputs": [],
   "source": [
    "df.iloc[np.r_[0:5,-5:0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhW79lgN6Qp5"
   },
   "outputs": [],
   "source": [
    "import time \n",
    "print(' start ' , time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(1451624400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTPIP31v-OJf"
   },
   "outputs": [],
   "source": [
    "time_index = pd.date_range('2016-01-01 05:00', periods=len(df),  freq='min')  \n",
    "time_index = pd.DatetimeIndex(time_index)\n",
    "df= df.set_index(time_index)\n",
    "#df = df.drop(['time'], axis=1)\n",
    "df.iloc[np.r_[0:5,-5:0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPFjsaqr6Qs5"
   },
   "outputs": [],
   "source": [
    "df=df.drop(['House overall','summary','icon'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sys--oHF6Qxb"
   },
   "outputs": [],
   "source": [
    "df['cloudCover'].replace(['cloudCover'], method='bfill', inplace=True)\n",
    "df['cloudCover'] = df['cloudCover'].astype('float')\n",
    "df['cloudCover'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kus8dqoe6Q0M"
   },
   "outputs": [],
   "source": [
    "df = df.resample('10T').mean()\n",
    "print(\"Shape of hourly data: {} --> n_rows = {}, n_cols = {}\".format(df.shape, df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lv1N4zcR6j3q"
   },
   "outputs": [],
   "source": [
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpdgpSXH6j7N"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AACDUXHpmFqU"
   },
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised_mimo(data, n_in, n_out, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [(df.columns[j]+'(t-%d)' % (i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [(df.columns[j]+'(t)') for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [(df.columns[j]+'%d(t+%d)' % (j, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0zzvPmymJrq"
   },
   "outputs": [],
   "source": [
    "reframed = series_to_supervised_mimo(df, 1, 1)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaxSUZOy6j_L"
   },
   "outputs": [],
   "source": [
    "x,y=reframed.loc[:,:],reframed.loc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qrhm9ld6kJK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "# Get the number of inputs and outputs from the dataset\n",
    "df_trainx=x_train.loc[:,'use(t-1)':'precipProbability(t-1)']\n",
    "df_testx=x_test.loc[:,'use(t-1)':'precipProbability(t-1)']\n",
    "df_trainy=y_train.loc[:,'use(t-1)':'precipProbability(t-1)']\n",
    "df_original=y_test.loc[:,'use(t)':'precipProbability(t)']\n",
    "\n",
    "n_inputs, n_outputs = df_trainx.shape[1], df_trainy.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFsKrpPU-lb3"
   },
   "outputs": [],
   "source": [
    "print(n_outputs,n_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYQne2bYjxS7"
   },
   "source": [
    "##Randomized_Grid_SearcgCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml5EA-uz7OS1"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "model = MultiOutputRegressor(GradientBoostingRegressor())\n",
    "\n",
    "hyperparameters = dict(estimator__learning_rate=[0.05, 0.1, 0.2, 0.5, 0.9],\n",
    "                     estimator__n_estimators=[20, 50, 100, 200, 300],\n",
    "                     estimator__criterion=['friedman_mse', 'mse'], estimator__min_samples_split=[2,3,5,7,9],\n",
    "                     estimator__max_depth=[2,5,10,20,30], estimator__min_samples_leaf=[1,2,3,4,5,7,9])\n",
    "\n",
    "randomized_search = RandomizedSearchCV(model, hyperparameters, random_state=0, n_iter=5, scoring=None,\n",
    "                                       n_jobs=2, refit=True, cv=5, verbose=True,\n",
    "                                       pre_dispatch='2*n_jobs', error_score='raise', return_train_score=True)\n",
    "\n",
    "hyperparameters_tuning = randomized_search.fit(df_trainx, df_trainy)\n",
    "print('Best Parameters = {}'.format(hyperparameters_tuning.best_params_))\n",
    "\n",
    "tuned_model = hyperparameters_tuning.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yle4K6ZSoAyK"
   },
   "outputs": [],
   "source": [
    "y_p=tuned_model.predict(df_testx)\n",
    "columns=df_original.columns\n",
    "y_p=pd.DataFrame(y_p,columns=columns)\n",
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oN3Z1H-IrFlC"
   },
   "outputs": [],
   "source": [
    "col=df_original.columns\n",
    "result = {\n",
    "        \n",
    "         \"rmse\": [],\n",
    "         \n",
    "         \"mae\": [],\n",
    "         \"r2\": [],\n",
    "         \"mape\":[],\n",
    "         \"variable\":[]\n",
    "    }\n",
    "    \n",
    "final_result = {\n",
    "        \n",
    "         \"rmse\": [],\n",
    "         \n",
    "         \"mae\": [],\n",
    "         \"r2\": [],\n",
    "         \"mape\":[],\n",
    "         \"variable\":[]}\n",
    "for col in col: \n",
    "  original = df_original[col].values\n",
    "  forecast = y_p[col].values\n",
    "  mae = round(mean_absolute_error(original,forecast),3)\n",
    "  r2 = round(r2_score(original,forecast),3)\n",
    "  rmse = round(mean_squared_error(original,forecast,squared=False),3)             \n",
    "  mape = round(mean_absolute_percentage_error(original,forecast),3)\n",
    "\n",
    "  result[\"rmse\"].append(rmse)\n",
    "  result[\"mae\"].append(mae)\n",
    "  result[\"r2\"].append(r2)\n",
    "  result[\"mape\"].append(mape)\n",
    "  \n",
    "  result[\"variable\"].append(col)\n",
    "        \n",
    "measures = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OX4hoqOaoXYj"
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "final_result = {\n",
    "    \"variable\": [],\n",
    "    \"rmse\": [],\n",
    "    # \"nrmse\": [],\n",
    "    \"mae\": [],\n",
    "    \"r2\": [],\n",
    "    \"mape\":[]\n",
    "}\n",
    "\n",
    "\n",
    "var = measures.groupby(\"variable\")\n",
    "\n",
    "for col in columns:\n",
    "    \n",
    "    var_agr = var.get_group(col)\n",
    "           \n",
    "    rmse = round(statistics.mean(var_agr.loc[:,'rmse']),3)\n",
    "    # nrmse = round(statistics.mean(var_agr.loc[:,'nrmse']),3)\n",
    "    mae = round(statistics.mean(var_agr.loc[:,'mae']),3)\n",
    "    r2 = round(statistics.mean(var_agr.loc[:,'r2']),3)\n",
    "    mape = round(statistics.mean(var_agr.loc[:,'mape']),3)\n",
    "\n",
    "    final_result[\"variable\"].append(col)\n",
    "    final_result[\"rmse\"].append(rmse)\n",
    "    # final_result[\"nrmse\"].append(nrmse)\n",
    "    final_result[\"mae\"].append(mae)\n",
    "    final_result[\"r2\"].append(r2)\n",
    "    final_result[\"mape\"].append(mape)\n",
    "        \n",
    "    print(f'Results: {(col,rmse,mae,r2,mape)}')\n",
    "        \n",
    "        \n",
    "final_measures_kpca = pd.DataFrame(final_result) \n",
    "\n",
    "print(\"Statistics MIMO (test): \")\n",
    "final_measures_kpca"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MIMO_regressor_GB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
